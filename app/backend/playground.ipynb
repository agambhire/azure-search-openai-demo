{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be0ba938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.filedatalake.aio import FileSystemClient\n",
    "from azure.identity.aio import (\n",
    "    AzureDeveloperCliCredential,\n",
    "    ManagedIdentityCredential,\n",
    "    get_bearer_token_provider,\n",
    ")\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fad455",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_USERSTORAGE_ACCOUNT=\"usersttlhc65hyz52oy\"\n",
    "AZURE_USERSTORAGE_CONTAINER=\"user-content\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664dcce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_oid = \"63e8dafc-039c-447b-9df0-6b2c9aec1df2\"\n",
    "original_user_query = \"Extract tables from 2013_contoso_products.pdf file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9052f378",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_credential = ManagedIdentityCredential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df51bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_blob_container_client = FileSystemClient(\n",
    "            f\"https://{AZURE_USERSTORAGE_ACCOUNT}.dfs.core.windows.net\",\n",
    "            AZURE_USERSTORAGE_CONTAINER,\n",
    "            credential=azure_credential,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b103d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\work\\Engagement\\EY-Tax-Payroll\\playground\\app\\backend\\.venv\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import os\n",
    "\n",
    "# Custom stopwords to ignore while matching\n",
    "custom_stopwords = {'merger', 'agreement', 'document', 'memo', 'file', 'note'}\n",
    "\n",
    "def clean_text(text):\n",
    "    # Lowercase, remove extension, replace _ with space, and remove stopwords\n",
    "    text = os.path.splitext(text)[0].replace('_', ' ').lower()\n",
    "    words = text.split()\n",
    "    return ' '.join([word for word in words if word not in custom_stopwords])\n",
    "\n",
    "def extract_matching_filename(input_string, filenames, threshold=70):\n",
    "    input_clean = clean_text(input_string)\n",
    "    matches = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        file_clean = clean_text(filename)\n",
    "        similarity = fuzz.partial_ratio(file_clean, input_clean)\n",
    "\n",
    "        if similarity >= threshold:\n",
    "            matches.append((filename, similarity))\n",
    "\n",
    "    matches.sort(key=lambda x: x[1], reverse=True)\n",
    "    return matches[0][0] if matches else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a874120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(user_query, all_paths):\n",
    "    files = []\n",
    "    try:\n",
    "        for path in all_paths:\n",
    "            print(path)\n",
    "            files.append(path.name.split('/')[-1])\n",
    "    except Exception as error:\n",
    "        print(\"Error listing uploaded files\", error)\n",
    "    file_mentioned_in_query = extract_matching_filename(user_query, files)\n",
    "    return file_mentioned_in_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b6314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Authenticate using DefaultAzureCredential\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "account_url = f\"https://{AZURE_USERSTORAGE_ACCOUNT}.blob.core.windows.net\"\n",
    "blob_service_client = BlobServiceClient(account_url=account_url, credential=credential)\n",
    "\n",
    "# Get the container and blob clients\n",
    "container_client = blob_service_client.get_container_client(AZURE_USERSTORAGE_CONTAINER)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c47767b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '63e8dafc-039c-447b-9df0-6b2c9aec1df2', 'container': 'user-content', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2025, 4, 29, 12, 3, 17, tzinfo=datetime.timezone.utc), 'etag': '0x8DD8715D4056180', 'size': 0, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/octet-stream', 'content_encoding': None, 'content_language': None, 'content_md5': None, 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2025, 4, 29, 12, 3, 17, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None}\n",
      "{'name': '63e8dafc-039c-447b-9df0-6b2c9aec1df2/2013_contoso_products.pdf', 'container': 'user-content', 'snapshot': None, 'version_id': None, 'is_current_version': None, 'blob_type': <BlobType.BLOCKBLOB: 'BlockBlob'>, 'metadata': {}, 'encrypted_metadata': None, 'last_modified': datetime.datetime(2025, 4, 29, 12, 3, 17, tzinfo=datetime.timezone.utc), 'etag': '0x8DD8715D416AE90', 'size': 276830, 'content_range': None, 'append_blob_committed_block_count': None, 'is_append_blob_sealed': None, 'page_blob_sequence_number': None, 'server_encrypted': True, 'copy': {'id': None, 'source': None, 'status': None, 'progress': None, 'completion_time': None, 'status_description': None, 'incremental_copy': None, 'destination_snapshot': None}, 'content_settings': {'content_type': 'application/octet-stream', 'content_encoding': None, 'content_language': None, 'content_md5': None, 'content_disposition': None, 'cache_control': None}, 'lease': {'status': 'unlocked', 'state': 'available', 'duration': None}, 'blob_tier': 'Hot', 'rehydrate_priority': None, 'blob_tier_change_time': None, 'blob_tier_inferred': True, 'deleted': None, 'deleted_time': None, 'remaining_retention_days': None, 'creation_time': datetime.datetime(2025, 4, 29, 12, 3, 17, tzinfo=datetime.timezone.utc), 'archive_status': None, 'encryption_key_sha256': None, 'encryption_scope': None, 'request_server_encrypted': None, 'object_replication_source_properties': [], 'object_replication_destination_policy': None, 'last_accessed_on': None, 'tag_count': None, 'tags': None, 'immutability_policy': {'expiry_time': None, 'policy_mode': None}, 'has_legal_hold': None, 'has_versions_only': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2013_contoso_products.pdf'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_paths = user_blob_container_client.get_paths(path=user_oid)\n",
    "all_paths = container_client.list_blobs()\n",
    "\n",
    "file_mentioned_by_client = get_file_name(original_user_query, all_paths)\n",
    "file_mentioned_by_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dca045ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob_client = container_client.get_blob_client('63e8dafc-039c-447b-9df0-6b2c9aec1df2/2013_contoso_products.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21c199f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Download the blob content to a buffer\n",
    "stream = BytesIO()\n",
    "blob_client.download_blob().readinto(stream)\n",
    "\n",
    "# Reset the buffer's position to the beginning\n",
    "stream.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf88c325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import hashlib\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "from abc import ABC\n",
    "from collections.abc import AsyncGenerator\n",
    "from glob import glob\n",
    "from typing import IO, Optional, Union\n",
    "\n",
    "class File:\n",
    "    \"\"\"\n",
    "    Represents a file stored either locally or in a data lake storage account\n",
    "    This file might contain access control information about which users or groups can access it\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, content: IO, acls: Optional[dict[str, list]] = None, url: Optional[str] = None):\n",
    "        self.content = content\n",
    "        self.acls = acls or {}\n",
    "        self.url = url\n",
    "\n",
    "    def filename(self):\n",
    "        return os.path.basename(self.content.name)\n",
    "\n",
    "    def file_extension(self):\n",
    "        return os.path.splitext(self.content.name)[1]\n",
    "\n",
    "    def filename_to_id(self):\n",
    "        filename_ascii = re.sub(\"[^0-9a-zA-Z_-]\", \"_\", self.filename())\n",
    "        filename_hash = base64.b16encode(self.filename().encode(\"utf-8\")).decode(\"ascii\")\n",
    "        acls_hash = \"\"\n",
    "        if self.acls:\n",
    "            acls_hash = base64.b16encode(str(self.acls).encode(\"utf-8\")).decode(\"ascii\")\n",
    "        return f\"file-{filename_ascii}-{filename_hash}{acls_hash}\"\n",
    "\n",
    "    def close(self):\n",
    "        if self.content:\n",
    "            self.content.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c248809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://usersttlhc65hyz52oy.blob.core.windows.net/user-content/63e8dafc-039c-447b-9df0-6b2c9aec1df2/2013_contoso_products.pdf'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "File(content=stream, acls={\"oids\": [user_oid]}, url=blob_client.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef412fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC\n",
    "from collections.abc import AsyncGenerator\n",
    "from typing import IO\n",
    "\n",
    "from collections.abc import Generator\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from azure.ai.documentintelligence.aio import DocumentIntelligenceClient\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "626948b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page:\n",
    "    \"\"\"\n",
    "    A single page from a document\n",
    "\n",
    "    Attributes:\n",
    "        page_num (int): Page number (0-indexed)\n",
    "        offset (int): If the text of the entire Document was concatenated into a single string, the index of the first character on the page. For example, if page 1 had the text \"hello\" and page 2 had the text \"world\", the offset of page 2 is 5 (\"hellow\")\n",
    "        text (str): The text of the page\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, page_num: int, offset: int, text: str):\n",
    "        self.page_num = page_num\n",
    "        self.offset = offset\n",
    "        self.text = text\n",
    "\n",
    "class Parser(ABC):\n",
    "    \"\"\"\n",
    "    Abstract parser that parses content into Page objects\n",
    "    \"\"\"\n",
    "\n",
    "    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n",
    "        if False:\n",
    "            yield  # pragma: no cover - this is necessary for mypy to type check\n",
    "\n",
    "\n",
    "class SplitPage:\n",
    "    \"\"\"\n",
    "    A section of a page that has been split into a smaller chunk.\n",
    "\n",
    "    Attributes:\n",
    "        page_num (int): Page number (0-indexed)\n",
    "        text (str): The text of the section\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, page_num: int, text: str):\n",
    "        self.page_num = page_num\n",
    "        self.text = text\n",
    "\n",
    "\n",
    "class TextSplitter(ABC):\n",
    "    \"\"\"\n",
    "    Splits a list of pages into smaller chunks\n",
    "    :param pages: The pages to split\n",
    "    :return: A generator of SplitPage\n",
    "    \"\"\"\n",
    "\n",
    "    def split_pages(self, pages: list[Page]) -> Generator[SplitPage, None, None]:\n",
    "        if False:\n",
    "            yield  # pragma: no cover - this is necessary for mypy to type check\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FileProcessor:\n",
    "    parser: Parser\n",
    "    splitter: TextSplitter\n",
    "\n",
    "class Section:\n",
    "    \"\"\"\n",
    "    A section of a page that is stored in a search service. These sections are used as context by Azure OpenAI service\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, split_page: SplitPage, content: File, category: Optional[str] = None):\n",
    "        self.split_page = split_page\n",
    "        self.content = content\n",
    "        self.category = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6bb47540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\typing.py:904: RuntimeWarning: coroutine 'ManagedIdentityCredential.get_token' was never awaited\n",
      "  code = compile(arg_to_compile, '<string>', 'eval')\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from abc import ABC\n",
    "from collections.abc import Awaitable\n",
    "from typing import Callable, Optional, Union\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "import aiohttp\n",
    "import tiktoken\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.credentials_async import AsyncTokenCredential\n",
    "from azure.identity.aio import get_bearer_token_provider\n",
    "from openai import AsyncAzureOpenAI, AsyncOpenAI, RateLimitError\n",
    "from tenacity import (\n",
    "    AsyncRetrying,\n",
    "    retry_if_exception_type,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "logger = logging.getLogger(\"scripts\")\n",
    "\n",
    "\n",
    "class EmbeddingBatch:\n",
    "    \"\"\"\n",
    "    Represents a batch of text that is going to be embedded\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts: list[str], token_length: int):\n",
    "        self.texts = texts\n",
    "        self.token_length = token_length\n",
    "\n",
    "\n",
    "class ExtraArgs(TypedDict, total=False):\n",
    "    dimensions: int\n",
    "\n",
    "\n",
    "class OpenAIEmbeddings(ABC):\n",
    "    \"\"\"\n",
    "    Contains common logic across both OpenAI and Azure OpenAI embedding services\n",
    "    Can split source text into batches for more efficient embedding calls\n",
    "    \"\"\"\n",
    "\n",
    "    SUPPORTED_BATCH_AOAI_MODEL = {\n",
    "        \"text-embedding-ada-002\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n",
    "        \"text-embedding-3-small\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n",
    "        \"text-embedding-3-large\": {\"token_limit\": 8100, \"max_batch_size\": 16},\n",
    "    }\n",
    "    SUPPORTED_DIMENSIONS_MODEL = {\n",
    "        \"text-embedding-ada-002\": False,\n",
    "        \"text-embedding-3-small\": True,\n",
    "        \"text-embedding-3-large\": True,\n",
    "    }\n",
    "\n",
    "    def __init__(self, open_ai_model_name: str, open_ai_dimensions: int, disable_batch: bool = False):\n",
    "        self.open_ai_model_name = open_ai_model_name\n",
    "        self.open_ai_dimensions = open_ai_dimensions\n",
    "        self.disable_batch = disable_batch\n",
    "\n",
    "    async def create_client(self) -> AsyncOpenAI:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def before_retry_sleep(self, retry_state):\n",
    "        logger.info(\"Rate limited on the OpenAI embeddings API, sleeping before retrying...\")\n",
    "\n",
    "    def calculate_token_length(self, text: str):\n",
    "        encoding = tiktoken.encoding_for_model(self.open_ai_model_name)\n",
    "        return len(encoding.encode(text))\n",
    "\n",
    "    def split_text_into_batches(self, texts: list[str]) -> list[EmbeddingBatch]:\n",
    "        batch_info = OpenAIEmbeddings.SUPPORTED_BATCH_AOAI_MODEL.get(self.open_ai_model_name)\n",
    "        if not batch_info:\n",
    "            raise NotImplementedError(\n",
    "                f\"Model {self.open_ai_model_name} is not supported with batch embedding operations\"\n",
    "            )\n",
    "\n",
    "        batch_token_limit = batch_info[\"token_limit\"]\n",
    "        batch_max_size = batch_info[\"max_batch_size\"]\n",
    "        batches: list[EmbeddingBatch] = []\n",
    "        batch: list[str] = []\n",
    "        batch_token_length = 0\n",
    "        for text in texts:\n",
    "            text_token_length = self.calculate_token_length(text)\n",
    "            if batch_token_length + text_token_length >= batch_token_limit and len(batch) > 0:\n",
    "                batches.append(EmbeddingBatch(batch, batch_token_length))\n",
    "                batch = []\n",
    "                batch_token_length = 0\n",
    "\n",
    "            batch.append(text)\n",
    "            batch_token_length = batch_token_length + text_token_length\n",
    "            if len(batch) == batch_max_size:\n",
    "                batches.append(EmbeddingBatch(batch, batch_token_length))\n",
    "                batch = []\n",
    "                batch_token_length = 0\n",
    "\n",
    "        if len(batch) > 0:\n",
    "            batches.append(EmbeddingBatch(batch, batch_token_length))\n",
    "\n",
    "        return batches\n",
    "\n",
    "    async def create_embedding_batch(self, texts: list[str], dimensions_args: ExtraArgs) -> list[list[float]]:\n",
    "        batches = self.split_text_into_batches(texts)\n",
    "        embeddings = []\n",
    "        client = await self.create_client()\n",
    "        for batch in batches:\n",
    "            async for attempt in AsyncRetrying(\n",
    "                retry=retry_if_exception_type(RateLimitError),\n",
    "                wait=wait_random_exponential(min=15, max=60),\n",
    "                stop=stop_after_attempt(15),\n",
    "                before_sleep=self.before_retry_sleep,\n",
    "            ):\n",
    "                with attempt:\n",
    "                    emb_response = await client.embeddings.create(\n",
    "                        model=self.open_ai_model_name, input=batch.texts, **dimensions_args\n",
    "                    )\n",
    "                    embeddings.extend([data.embedding for data in emb_response.data])\n",
    "                    logger.info(\n",
    "                        \"Computed embeddings in batch. Batch size: %d, Token count: %d\",\n",
    "                        len(batch.texts),\n",
    "                        batch.token_length,\n",
    "                    )\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    async def create_embedding_single(self, text: str, dimensions_args: ExtraArgs) -> list[float]:\n",
    "        client = await self.create_client()\n",
    "        async for attempt in AsyncRetrying(\n",
    "            retry=retry_if_exception_type(RateLimitError),\n",
    "            wait=wait_random_exponential(min=15, max=60),\n",
    "            stop=stop_after_attempt(15),\n",
    "            before_sleep=self.before_retry_sleep,\n",
    "        ):\n",
    "            with attempt:\n",
    "                emb_response = await client.embeddings.create(\n",
    "                    model=self.open_ai_model_name, input=text, **dimensions_args\n",
    "                )\n",
    "                logger.info(\"Computed embedding for text section. Character count: %d\", len(text))\n",
    "\n",
    "        return emb_response.data[0].embedding\n",
    "\n",
    "    async def create_embeddings(self, texts: list[str]) -> list[list[float]]:\n",
    "\n",
    "        dimensions_args: ExtraArgs = (\n",
    "            {\"dimensions\": self.open_ai_dimensions}\n",
    "            if OpenAIEmbeddings.SUPPORTED_DIMENSIONS_MODEL.get(self.open_ai_model_name)\n",
    "            else {}\n",
    "        )\n",
    "\n",
    "        if not self.disable_batch and self.open_ai_model_name in OpenAIEmbeddings.SUPPORTED_BATCH_AOAI_MODEL:\n",
    "            return await self.create_embedding_batch(texts, dimensions_args)\n",
    "\n",
    "        return [await self.create_embedding_single(text, dimensions_args) for text in texts]\n",
    "\n",
    "\n",
    "class AzureOpenAIEmbeddingService(OpenAIEmbeddings):\n",
    "    \"\"\"\n",
    "    Class for using Azure OpenAI embeddings\n",
    "    To learn more please visit https://learn.microsoft.com/azure/ai-services/openai/concepts/understand-embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        open_ai_service: Union[str, None],\n",
    "        open_ai_deployment: Union[str, None],\n",
    "        open_ai_model_name: str,\n",
    "        open_ai_dimensions: int,\n",
    "        open_ai_api_version: str,\n",
    "        credential: Union[AsyncTokenCredential, AzureKeyCredential],\n",
    "        open_ai_custom_url: Union[str, None] = None,\n",
    "        disable_batch: bool = False,\n",
    "    ):\n",
    "        super().__init__(open_ai_model_name, open_ai_dimensions, disable_batch)\n",
    "        self.open_ai_service = open_ai_service\n",
    "        if open_ai_service:\n",
    "            self.open_ai_endpoint = f\"https://{open_ai_service}.openai.azure.com\"\n",
    "        elif open_ai_custom_url:\n",
    "            self.open_ai_endpoint = open_ai_custom_url\n",
    "        else:\n",
    "            raise ValueError(\"Either open_ai_service or open_ai_custom_url must be provided\")\n",
    "        self.open_ai_deployment = open_ai_deployment\n",
    "        self.open_ai_api_version = open_ai_api_version\n",
    "        self.credential = credential\n",
    "\n",
    "    async def create_client(self) -> AsyncOpenAI:\n",
    "        class AuthArgs(TypedDict, total=False):\n",
    "            api_key: str\n",
    "            azure_ad_token_provider: Callable[[], Union[str, Awaitable[str]]]\n",
    "\n",
    "        auth_args = AuthArgs()\n",
    "        if isinstance(self.credential, AzureKeyCredential):\n",
    "            auth_args[\"api_key\"] = self.credential.key\n",
    "        elif isinstance(self.credential, AsyncTokenCredential):\n",
    "            auth_args[\"azure_ad_token_provider\"] = get_bearer_token_provider(\n",
    "                self.credential, \"https://cognitiveservices.azure.com/.default\"\n",
    "            )\n",
    "        else:\n",
    "            raise TypeError(\"Invalid credential type\")\n",
    "\n",
    "        return AsyncAzureOpenAI(\n",
    "            azure_endpoint=self.open_ai_endpoint,\n",
    "            azure_deployment=self.open_ai_deployment,\n",
    "            api_version=self.open_ai_api_version,\n",
    "            **auth_args,\n",
    "        )\n",
    "\n",
    "\n",
    "class OpenAIEmbeddingService(OpenAIEmbeddings):\n",
    "    \"\"\"\n",
    "    Class for using OpenAI embeddings\n",
    "    To learn more please visit https://platform.openai.com/docs/guides/embeddings\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        open_ai_model_name: str,\n",
    "        open_ai_dimensions: int,\n",
    "        credential: str,\n",
    "        organization: Optional[str] = None,\n",
    "        disable_batch: bool = False,\n",
    "    ):\n",
    "        super().__init__(open_ai_model_name, open_ai_dimensions, disable_batch)\n",
    "        self.credential = credential\n",
    "        self.organization = organization\n",
    "\n",
    "    async def create_client(self) -> AsyncOpenAI:\n",
    "        return AsyncOpenAI(api_key=self.credential, organization=self.organization)\n",
    "\n",
    "\n",
    "class ImageEmbeddings:\n",
    "    \"\"\"\n",
    "    Class for using image embeddings from Azure AI Vision\n",
    "    To learn more, please visit https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/image-retrieval#call-the-vectorize-image-api\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, endpoint: str, token_provider: Callable[[], Awaitable[str]]):\n",
    "        self.token_provider = token_provider\n",
    "        self.endpoint = endpoint\n",
    "\n",
    "    async def create_embeddings(self, blob_urls: list[str]) -> list[list[float]]:\n",
    "        endpoint = urljoin(self.endpoint, \"computervision/retrieval:vectorizeImage\")\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        params = {\"api-version\": \"2023-02-01-preview\", \"modelVersion\": \"latest\"}\n",
    "        headers[\"Authorization\"] = \"Bearer \" + await self.token_provider()\n",
    "\n",
    "        embeddings: list[list[float]] = []\n",
    "        async with aiohttp.ClientSession(headers=headers) as session:\n",
    "            for blob_url in blob_urls:\n",
    "                async for attempt in AsyncRetrying(\n",
    "                    retry=retry_if_exception_type(Exception),\n",
    "                    wait=wait_random_exponential(min=15, max=60),\n",
    "                    stop=stop_after_attempt(15),\n",
    "                    before_sleep=self.before_retry_sleep,\n",
    "                ):\n",
    "                    with attempt:\n",
    "                        body = {\"url\": blob_url}\n",
    "                        async with session.post(url=endpoint, params=params, json=body) as resp:\n",
    "                            resp_json = await resp.json()\n",
    "                            embeddings.append(resp_json[\"vector\"])\n",
    "\n",
    "        return embeddings\n",
    "\n",
    "    def before_retry_sleep(self, retry_state):\n",
    "        logger.info(\"Rate limited on the Vision embeddings API, sleeping before retrying...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ce71b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def parse_file(\n",
    "    file: File,\n",
    "    file_processors: dict[str, FileProcessor],\n",
    "    category: Optional[str] = None,\n",
    "    image_embeddings: Optional[ImageEmbeddings] = None,\n",
    ") -> list[Section]:\n",
    "    key = file.file_extension().lower()\n",
    "    processor = file_processors.get(key)\n",
    "    if processor is None:\n",
    "        logger.info(\"Skipping '%s', no parser found.\", file.filename())\n",
    "        return []\n",
    "    logger.info(\"Ingesting '%s'\", file.filename())\n",
    "    pages = [page async for page in processor.parser.parse(content=file.content)]\n",
    "    logger.info(\"Splitting '%s' into sections\", file.filename())\n",
    "    if image_embeddings:\n",
    "        logger.warning(\"Each page will be split into smaller chunks of text, but images will be of the entire page.\")\n",
    "    sections = [\n",
    "        Section(split_page, content=file, category=category) for split_page in processor.splitter.split_pages(pages)\n",
    "    ]\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4166c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetchUserFileStrategy:\n",
    "    \"\"\"\n",
    "    Strategy for parsing a file that has already been uploaded to a ADLS2 storage account\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_processors: dict[str, FileProcessor],\n",
    "    ):\n",
    "        self.file_processors = file_processors\n",
    "\n",
    "    async def fetch_file(self, file: File):\n",
    "        if self.image_embeddings:\n",
    "            logging.warning(\"Image embeddings are not currently supported for the user upload feature\")\n",
    "        sections = await parse_file(file, self.file_processors)\n",
    "        return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d1a42ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from abc import ABC\n",
    "from collections.abc import Generator\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "logger = logging.getLogger(\"scripts\")\n",
    "\n",
    "\n",
    "class TextSplitter(ABC):\n",
    "    \"\"\"\n",
    "    Splits a list of pages into smaller chunks\n",
    "    :param pages: The pages to split\n",
    "    :return: A generator of SplitPage\n",
    "    \"\"\"\n",
    "\n",
    "    def split_pages(self, pages: list[Page]) -> Generator[SplitPage, None, None]:\n",
    "        if False:\n",
    "            yield  # pragma: no cover - this is necessary for mypy to type check\n",
    "\n",
    "\n",
    "ENCODING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "STANDARD_WORD_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]\n",
    "\n",
    "# See W3C document https://www.w3.org/TR/jlreq/#cl-01\n",
    "CJK_WORD_BREAKS = [\n",
    "    \"、\",\n",
    "    \"，\",\n",
    "    \"；\",\n",
    "    \"：\",\n",
    "    \"（\",\n",
    "    \"）\",\n",
    "    \"【\",\n",
    "    \"】\",\n",
    "    \"「\",\n",
    "    \"」\",\n",
    "    \"『\",\n",
    "    \"』\",\n",
    "    \"〔\",\n",
    "    \"〕\",\n",
    "    \"〈\",\n",
    "    \"〉\",\n",
    "    \"《\",\n",
    "    \"》\",\n",
    "    \"〖\",\n",
    "    \"〗\",\n",
    "    \"〘\",\n",
    "    \"〙\",\n",
    "    \"〚\",\n",
    "    \"〛\",\n",
    "    \"〝\",\n",
    "    \"〞\",\n",
    "    \"〟\",\n",
    "    \"〰\",\n",
    "    \"–\",\n",
    "    \"—\",\n",
    "    \"‘\",\n",
    "    \"’\",\n",
    "    \"‚\",\n",
    "    \"‛\",\n",
    "    \"“\",\n",
    "    \"”\",\n",
    "    \"„\",\n",
    "    \"‟\",\n",
    "    \"‹\",\n",
    "    \"›\",\n",
    "]\n",
    "\n",
    "STANDARD_SENTENCE_ENDINGS = [\".\", \"!\", \"?\"]\n",
    "\n",
    "# See CL05 and CL06, based on JIS X 4051:2004\n",
    "# https://www.w3.org/TR/jlreq/#cl-04\n",
    "CJK_SENTENCE_ENDINGS = [\"。\", \"！\", \"？\", \"‼\", \"⁇\", \"⁈\", \"⁉\"]\n",
    "\n",
    "# NB: text-embedding-3-XX is the same BPE as text-embedding-ada-002\n",
    "bpe = tiktoken.encoding_for_model(ENCODING_MODEL)\n",
    "\n",
    "DEFAULT_OVERLAP_PERCENT = 10  # See semantic search article for 10% overlap performance\n",
    "DEFAULT_SECTION_LENGTH = 1000  # Roughly 400-500 tokens for English\n",
    "\n",
    "\n",
    "class SentenceTextSplitter(TextSplitter):\n",
    "    \"\"\"\n",
    "    Class that splits pages into smaller chunks. This is required because embedding models may not be able to analyze an entire page at once\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_tokens_per_section: int = 500):\n",
    "        self.sentence_endings = STANDARD_SENTENCE_ENDINGS + CJK_SENTENCE_ENDINGS\n",
    "        self.word_breaks = STANDARD_WORD_BREAKS + CJK_WORD_BREAKS\n",
    "        self.max_section_length = DEFAULT_SECTION_LENGTH\n",
    "        self.sentence_search_limit = 100\n",
    "        self.max_tokens_per_section = max_tokens_per_section\n",
    "        self.section_overlap = int(self.max_section_length * DEFAULT_OVERLAP_PERCENT / 100)\n",
    "\n",
    "    def split_page_by_max_tokens(self, page_num: int, text: str) -> Generator[SplitPage, None, None]:\n",
    "        \"\"\"\n",
    "        Recursively splits page by maximum number of tokens to better handle languages with higher token/word ratios.\n",
    "        \"\"\"\n",
    "        tokens = bpe.encode(text)\n",
    "        if len(tokens) <= self.max_tokens_per_section:\n",
    "            # Section is already within max tokens, return\n",
    "            yield SplitPage(page_num=page_num, text=text)\n",
    "        else:\n",
    "            # Start from the center and try and find the closest sentence ending by spiralling outward.\n",
    "            # IF we get to the outer thirds, then just split in half with a 5% overlap\n",
    "            start = int(len(text) // 2)\n",
    "            pos = 0\n",
    "            boundary = int(len(text) // 3)\n",
    "            split_position = -1\n",
    "            while start - pos > boundary:\n",
    "                if text[start - pos] in self.sentence_endings:\n",
    "                    split_position = start - pos\n",
    "                    break\n",
    "                elif text[start + pos] in self.sentence_endings:\n",
    "                    split_position = start + pos\n",
    "                    break\n",
    "                else:\n",
    "                    pos += 1\n",
    "\n",
    "            if split_position > 0:\n",
    "                first_half = text[: split_position + 1]\n",
    "                second_half = text[split_position + 1 :]\n",
    "            else:\n",
    "                # Split page in half and call function again\n",
    "                # Overlap first and second halves by DEFAULT_OVERLAP_PERCENT%\n",
    "                middle = int(len(text) // 2)\n",
    "                overlap = int(len(text) * (DEFAULT_OVERLAP_PERCENT / 100))\n",
    "                first_half = text[: middle + overlap]\n",
    "                second_half = text[middle - overlap :]\n",
    "            yield from self.split_page_by_max_tokens(page_num, first_half)\n",
    "            yield from self.split_page_by_max_tokens(page_num, second_half)\n",
    "\n",
    "    def split_pages(self, pages: list[Page]) -> Generator[SplitPage, None, None]:\n",
    "        def find_page(offset):\n",
    "            num_pages = len(pages)\n",
    "            for i in range(num_pages - 1):\n",
    "                if offset >= pages[i].offset and offset < pages[i + 1].offset:\n",
    "                    return pages[i].page_num\n",
    "            return pages[num_pages - 1].page_num\n",
    "\n",
    "        all_text = \"\".join(page.text for page in pages)\n",
    "        if len(all_text.strip()) == 0:\n",
    "            return\n",
    "\n",
    "        length = len(all_text)\n",
    "        if length <= self.max_section_length:\n",
    "            yield from self.split_page_by_max_tokens(page_num=find_page(0), text=all_text)\n",
    "            return\n",
    "\n",
    "        start = 0\n",
    "        end = length\n",
    "        while start + self.section_overlap < length:\n",
    "            last_word = -1\n",
    "            end = start + self.max_section_length\n",
    "\n",
    "            if end > length:\n",
    "                end = length\n",
    "            else:\n",
    "                # Try to find the end of the sentence\n",
    "                while (\n",
    "                    end < length\n",
    "                    and (end - start - self.max_section_length) < self.sentence_search_limit\n",
    "                    and all_text[end] not in self.sentence_endings\n",
    "                ):\n",
    "                    if all_text[end] in self.word_breaks:\n",
    "                        last_word = end\n",
    "                    end += 1\n",
    "                if end < length and all_text[end] not in self.sentence_endings and last_word > 0:\n",
    "                    end = last_word  # Fall back to at least keeping a whole word\n",
    "            if end < length:\n",
    "                end += 1\n",
    "\n",
    "            # Try to find the start of the sentence or at least a whole word boundary\n",
    "            last_word = -1\n",
    "            while (\n",
    "                start > 0\n",
    "                and start > end - self.max_section_length - 2 * self.sentence_search_limit\n",
    "                and all_text[start] not in self.sentence_endings\n",
    "            ):\n",
    "                if all_text[start] in self.word_breaks:\n",
    "                    last_word = start\n",
    "                start -= 1\n",
    "            if all_text[start] not in self.sentence_endings and last_word > 0:\n",
    "                start = last_word\n",
    "            if start > 0:\n",
    "                start += 1\n",
    "\n",
    "            section_text = all_text[start:end]\n",
    "            yield from self.split_page_by_max_tokens(page_num=find_page(start), text=section_text)\n",
    "\n",
    "            last_figure_start = section_text.rfind(\"<figure\")\n",
    "            if last_figure_start > 2 * self.sentence_search_limit and last_figure_start > section_text.rfind(\n",
    "                \"</figure\"\n",
    "            ):\n",
    "                # If the section ends with an unclosed figure, we need to start the next section with the figure.\n",
    "                start = min(end - self.section_overlap, start + last_figure_start)\n",
    "                logger.info(\n",
    "                    f\"Section ends with unclosed figure, starting next section with the figure at page {find_page(start)} offset {start} figure start {last_figure_start}\"\n",
    "                )\n",
    "            else:\n",
    "                start = end - self.section_overlap\n",
    "\n",
    "        if start + self.section_overlap < end:\n",
    "            yield from self.split_page_by_max_tokens(page_num=find_page(start), text=all_text[start:end])\n",
    "\n",
    "\n",
    "class SimpleTextSplitter(TextSplitter):\n",
    "    \"\"\"\n",
    "    Class that splits pages into smaller chunks based on a max object length. It is not aware of the content of the page.\n",
    "    This is required because embedding models may not be able to analyze an entire page at once\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_object_length: int = 1000):\n",
    "        self.max_object_length = max_object_length\n",
    "\n",
    "    def split_pages(self, pages: list[Page]) -> Generator[SplitPage, None, None]:\n",
    "        all_text = \"\".join(page.text for page in pages)\n",
    "        if len(all_text.strip()) == 0:\n",
    "            return\n",
    "\n",
    "        length = len(all_text)\n",
    "        if length <= self.max_object_length:\n",
    "            yield SplitPage(page_num=0, text=all_text)\n",
    "            return\n",
    "\n",
    "        # its too big, so we need to split it\n",
    "        for i in range(0, length, self.max_object_length):\n",
    "            yield SplitPage(page_num=i // self.max_object_length, text=all_text[i : i + self.max_object_length])\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ab81aa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "import io\n",
    "import logging\n",
    "from collections.abc import AsyncGenerator\n",
    "from enum import Enum\n",
    "from typing import IO, Union\n",
    "\n",
    "import pymupdf\n",
    "from azure.ai.documentintelligence.aio import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import (\n",
    "    AnalyzeDocumentRequest,\n",
    "    AnalyzeResult,\n",
    "    DocumentFigure,\n",
    "    DocumentTable,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.credentials_async import AsyncTokenCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from PIL import Image\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1b8362ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LocalPdfParser(Parser):\n",
    "    \"\"\"\n",
    "    Concrete parser backed by PyPDF that can parse PDFs into pages\n",
    "    To learn more, please visit https://pypi.org/project/pypdf/\n",
    "    \"\"\"\n",
    "\n",
    "    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n",
    "        logger.info(\"Extracting text from '%s' using local PDF parser (pypdf)\", content.name)\n",
    "\n",
    "        reader = PdfReader(content)\n",
    "        pages = reader.pages\n",
    "        offset = 0\n",
    "        for page_num, p in enumerate(pages):\n",
    "            page_text = p.extract_text()\n",
    "            yield Page(page_num=page_num, offset=offset, text=page_text)\n",
    "            offset += len(page_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5622da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from abc import ABC\n",
    "\n",
    "import aiohttp\n",
    "from azure.core.credentials_async import AsyncTokenCredential\n",
    "from azure.identity.aio import get_bearer_token_provider\n",
    "from rich.progress import Progress\n",
    "from tenacity import retry, retry_if_exception_type, stop_after_attempt, wait_fixed\n",
    "\n",
    "logger = logging.getLogger(\"scripts\")\n",
    "\n",
    "\n",
    "class MediaDescriber(ABC):\n",
    "\n",
    "    async def describe_image(self, image_bytes) -> str:\n",
    "        raise NotImplementedError  # pragma: no cover\n",
    "\n",
    "\n",
    "class ContentUnderstandingDescriber:\n",
    "    CU_API_VERSION = \"2024-12-01-preview\"\n",
    "\n",
    "    analyzer_schema = {\n",
    "        \"analyzerId\": \"image_analyzer\",\n",
    "        \"name\": \"Image understanding\",\n",
    "        \"description\": \"Extract detailed structured information from images extracted from documents.\",\n",
    "        \"baseAnalyzerId\": \"prebuilt-image\",\n",
    "        \"scenario\": \"image\",\n",
    "        \"config\": {\"returnDetails\": False},\n",
    "        \"fieldSchema\": {\n",
    "            \"name\": \"ImageInformation\",\n",
    "            \"descriptions\": \"Description of image.\",\n",
    "            \"fields\": {\n",
    "                \"Description\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Description of the image. If the image has a title, start with the title. Include a 2-sentence summary. If the image is a chart, diagram, or table, include the underlying data in an HTML table tag, with accurate numbers. If the image is a chart, describe any axis or legends. The only allowed HTML tags are the table/thead/tr/td/tbody tags.\",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    def __init__(self, endpoint: str, credential: AsyncTokenCredential):\n",
    "        self.endpoint = endpoint\n",
    "        self.credential = credential\n",
    "\n",
    "    async def poll_api(self, session, poll_url, headers):\n",
    "\n",
    "        @retry(stop=stop_after_attempt(60), wait=wait_fixed(2), retry=retry_if_exception_type(ValueError))\n",
    "        async def poll():\n",
    "            async with session.get(poll_url, headers=headers) as response:\n",
    "                response.raise_for_status()\n",
    "                response_json = await response.json()\n",
    "                if response_json[\"status\"] == \"Failed\":\n",
    "                    raise Exception(\"Failed\")\n",
    "                if response_json[\"status\"] == \"Running\":\n",
    "                    raise ValueError(\"Running\")\n",
    "                return response_json\n",
    "\n",
    "        return await poll()\n",
    "\n",
    "    async def create_analyzer(self):\n",
    "        logger.info(\"Creating analyzer '%s'...\", self.analyzer_schema[\"analyzerId\"])\n",
    "\n",
    "        token_provider = get_bearer_token_provider(self.credential, \"https://cognitiveservices.azure.com/.default\")\n",
    "        token = await token_provider()\n",
    "        headers = {\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"}\n",
    "        params = {\"api-version\": self.CU_API_VERSION}\n",
    "        analyzer_id = self.analyzer_schema[\"analyzerId\"]\n",
    "        cu_endpoint = f\"{self.endpoint}/contentunderstanding/analyzers/{analyzer_id}\"\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.put(\n",
    "                url=cu_endpoint, params=params, headers=headers, json=self.analyzer_schema\n",
    "            ) as response:\n",
    "                if response.status == 409:\n",
    "                    logger.info(\"Analyzer '%s' already exists.\", analyzer_id)\n",
    "                    return\n",
    "                elif response.status != 201:\n",
    "                    data = await response.text()\n",
    "                    raise Exception(\"Error creating analyzer\", data)\n",
    "                else:\n",
    "                    poll_url = response.headers.get(\"Operation-Location\")\n",
    "\n",
    "            with Progress() as progress:\n",
    "                progress.add_task(\"Creating analyzer...\", total=None, start=False)\n",
    "                await self.poll_api(session, poll_url, headers)\n",
    "\n",
    "    async def describe_image(self, image_bytes: bytes) -> str:\n",
    "        logger.info(\"Sending image to Azure Content Understanding service...\")\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            token = await self.credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "            headers = {\"Authorization\": \"Bearer \" + token.token}\n",
    "            params = {\"api-version\": self.CU_API_VERSION}\n",
    "            analyzer_name = self.analyzer_schema[\"analyzerId\"]\n",
    "            async with session.post(\n",
    "                url=f\"{self.endpoint}/contentunderstanding/analyzers/{analyzer_name}:analyze\",\n",
    "                params=params,\n",
    "                headers=headers,\n",
    "                data=image_bytes,\n",
    "            ) as response:\n",
    "                response.raise_for_status()\n",
    "                poll_url = response.headers[\"Operation-Location\"]\n",
    "\n",
    "                with Progress() as progress:\n",
    "                    progress.add_task(\"Processing...\", total=None, start=False)\n",
    "                    results = await self.poll_api(session, poll_url, headers)\n",
    "\n",
    "                fields = results[\"result\"][\"contents\"][0][\"fields\"]\n",
    "                return fields[\"Description\"][\"valueString\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8108ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentAnalysisParser(Parser):\n",
    "    \"\"\"\n",
    "    Concrete parser backed by Azure AI Document Intelligence that can parse many document formats into pages\n",
    "    To learn more, please visit https://learn.microsoft.com/azure/ai-services/document-intelligence/overview\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        endpoint: str,\n",
    "        credential: Union[AsyncTokenCredential, AzureKeyCredential],\n",
    "        model_id=\"prebuilt-layout\",\n",
    "        use_content_understanding=True,\n",
    "        content_understanding_endpoint: Union[str, None] = None,\n",
    "    ):\n",
    "        self.model_id = model_id\n",
    "        self.endpoint = endpoint\n",
    "        self.credential = credential\n",
    "        self.use_content_understanding = use_content_understanding\n",
    "        self.content_understanding_endpoint = content_understanding_endpoint\n",
    "\n",
    "    async def parse(self, content: IO) -> AsyncGenerator[Page, None]:\n",
    "        logger.info(\"Extracting text from '%s' using Azure Document Intelligence\", content.name)\n",
    "\n",
    "        async with DocumentIntelligenceClient(\n",
    "            endpoint=self.endpoint, credential=self.credential\n",
    "        ) as document_intelligence_client:\n",
    "            file_analyzed = False\n",
    "            if self.use_content_understanding:\n",
    "                if self.content_understanding_endpoint is None:\n",
    "                    raise ValueError(\"Content Understanding is enabled but no endpoint was provided\")\n",
    "                if isinstance(self.credential, AzureKeyCredential):\n",
    "                    raise ValueError(\n",
    "                        \"AzureKeyCredential is not supported for Content Understanding, use keyless auth instead\"\n",
    "                    )\n",
    "                cu_describer = ContentUnderstandingDescriber(self.content_understanding_endpoint, self.credential)\n",
    "                content_bytes = content.read()\n",
    "                try:\n",
    "                    poller = await document_intelligence_client.begin_analyze_document(\n",
    "                        model_id=\"prebuilt-layout\",\n",
    "                        analyze_request=AnalyzeDocumentRequest(bytes_source=content_bytes),\n",
    "                        output=[\"figures\"],\n",
    "                        features=[\"ocrHighResolution\"],\n",
    "                        output_content_format=\"markdown\",\n",
    "                    )\n",
    "                    doc_for_pymupdf = pymupdf.open(stream=io.BytesIO(content_bytes))\n",
    "                    file_analyzed = True\n",
    "                except HttpResponseError as e:\n",
    "                    content.seek(0)\n",
    "                    if e.error and e.error.code == \"InvalidArgument\":\n",
    "                        logger.error(\n",
    "                            \"This document type does not support media description. Proceeding with standard analysis.\"\n",
    "                        )\n",
    "                    else:\n",
    "                        logger.error(\n",
    "                            \"Unexpected error analyzing document for media description: %s. Proceeding with standard analysis.\",\n",
    "                            e,\n",
    "                        )\n",
    "\n",
    "            if file_analyzed is False:\n",
    "                poller = await document_intelligence_client.begin_analyze_document(\n",
    "                    model_id=self.model_id, analyze_request=content, content_type=\"application/octet-stream\"\n",
    "                )\n",
    "            analyze_result: AnalyzeResult = await poller.result()\n",
    "\n",
    "            offset = 0\n",
    "            for page in analyze_result.pages:\n",
    "                tables_on_page = [\n",
    "                    table\n",
    "                    for table in (analyze_result.tables or [])\n",
    "                    if table.bounding_regions and table.bounding_regions[0].page_number == page.page_number\n",
    "                ]\n",
    "                figures_on_page = []\n",
    "                if self.use_content_understanding:\n",
    "                    figures_on_page = [\n",
    "                        figure\n",
    "                        for figure in (analyze_result.figures or [])\n",
    "                        if figure.bounding_regions and figure.bounding_regions[0].page_number == page.page_number\n",
    "                    ]\n",
    "\n",
    "                class ObjectType(Enum):\n",
    "                    NONE = -1\n",
    "                    TABLE = 0\n",
    "                    FIGURE = 1\n",
    "\n",
    "                page_offset = page.spans[0].offset\n",
    "                page_length = page.spans[0].length\n",
    "                mask_chars: list[tuple[ObjectType, Union[int, None]]] = [(ObjectType.NONE, None)] * page_length\n",
    "                # mark all positions of the table spans in the page\n",
    "                for table_idx, table in enumerate(tables_on_page):\n",
    "                    for span in table.spans:\n",
    "                        # replace all table spans with \"table_id\" in table_chars array\n",
    "                        for i in range(span.length):\n",
    "                            idx = span.offset - page_offset + i\n",
    "                            if idx >= 0 and idx < page_length:\n",
    "                                mask_chars[idx] = (ObjectType.TABLE, table_idx)\n",
    "                # mark all positions of the figure spans in the page\n",
    "                for figure_idx, figure in enumerate(figures_on_page):\n",
    "                    for span in figure.spans:\n",
    "                        # replace all figure spans with \"figure_id\" in figure_chars array\n",
    "                        for i in range(span.length):\n",
    "                            idx = span.offset - page_offset + i\n",
    "                            if idx >= 0 and idx < page_length:\n",
    "                                mask_chars[idx] = (ObjectType.FIGURE, figure_idx)\n",
    "\n",
    "                # build page text by replacing characters in table spans with table html\n",
    "                page_text = \"\"\n",
    "                added_objects = set()  # set of object types todo mypy\n",
    "                for idx, mask_char in enumerate(mask_chars):\n",
    "                    object_type, object_idx = mask_char\n",
    "                    if object_type == ObjectType.NONE:\n",
    "                        page_text += analyze_result.content[page_offset + idx]\n",
    "                    elif object_type == ObjectType.TABLE:\n",
    "                        if object_idx is None:\n",
    "                            raise ValueError(\"Expected object_idx to be set\")\n",
    "                        if mask_char not in added_objects:\n",
    "                            page_text += DocumentAnalysisParser.table_to_html(tables_on_page[object_idx])\n",
    "                            added_objects.add(mask_char)\n",
    "                    elif object_type == ObjectType.FIGURE:\n",
    "                        if cu_describer is None:\n",
    "                            raise ValueError(\"cu_describer should not be None, unable to describe figure\")\n",
    "                        if object_idx is None:\n",
    "                            raise ValueError(\"Expected object_idx to be set\")\n",
    "                        if mask_char not in added_objects:\n",
    "                            figure_html = await DocumentAnalysisParser.figure_to_html(\n",
    "                                doc_for_pymupdf, figures_on_page[object_idx], cu_describer\n",
    "                            )\n",
    "                            page_text += figure_html\n",
    "                            added_objects.add(mask_char)\n",
    "                # We remove these comments since they are not needed and skew the page numbers\n",
    "                page_text = page_text.replace(\"<!-- PageBreak -->\", \"\")\n",
    "                # We remove excess newlines at the beginning and end of the page\n",
    "                page_text = page_text.strip()\n",
    "                yield Page(page_num=page.page_number - 1, offset=offset, text=page_text)\n",
    "                offset += len(page_text)\n",
    "\n",
    "    @staticmethod\n",
    "    async def figure_to_html(\n",
    "        doc: pymupdf.Document, figure: DocumentFigure, cu_describer: ContentUnderstandingDescriber\n",
    "    ) -> str:\n",
    "        figure_title = (figure.caption and figure.caption.content) or \"\"\n",
    "        logger.info(\"Describing figure %s with title '%s'\", figure.id, figure_title)\n",
    "        if not figure.bounding_regions:\n",
    "            return f\"<figure><figcaption>{figure_title}</figcaption></figure>\"\n",
    "        if len(figure.bounding_regions) > 1:\n",
    "            logger.warning(\"Figure %s has more than one bounding region, using the first one\", figure.id)\n",
    "        first_region = figure.bounding_regions[0]\n",
    "        # To learn more about bounding regions, see https://aka.ms/bounding-region\n",
    "        bounding_box = (\n",
    "            first_region.polygon[0],  # x0 (left)\n",
    "            first_region.polygon[1],  # y0 (top\n",
    "            first_region.polygon[4],  # x1 (right)\n",
    "            first_region.polygon[5],  # y1 (bottom)\n",
    "        )\n",
    "        page_number = first_region[\"pageNumber\"]  # 1-indexed\n",
    "        cropped_img = DocumentAnalysisParser.crop_image_from_pdf_page(doc, page_number - 1, bounding_box)\n",
    "        figure_description = await cu_describer.describe_image(cropped_img)\n",
    "        return f\"<figure><figcaption>{figure_title}<br>{figure_description}</figcaption></figure>\"\n",
    "\n",
    "    @staticmethod\n",
    "    def table_to_html(table: DocumentTable):\n",
    "        table_html = \"<figure><table>\"\n",
    "        rows = [\n",
    "            sorted([cell for cell in table.cells if cell.row_index == i], key=lambda cell: cell.column_index)\n",
    "            for i in range(table.row_count)\n",
    "        ]\n",
    "        for row_cells in rows:\n",
    "            table_html += \"<tr>\"\n",
    "            for cell in row_cells:\n",
    "                tag = \"th\" if (cell.kind == \"columnHeader\" or cell.kind == \"rowHeader\") else \"td\"\n",
    "                cell_spans = \"\"\n",
    "                if cell.column_span is not None and cell.column_span > 1:\n",
    "                    cell_spans += f\" colSpan={cell.column_span}\"\n",
    "                if cell.row_span is not None and cell.row_span > 1:\n",
    "                    cell_spans += f\" rowSpan={cell.row_span}\"\n",
    "                table_html += f\"<{tag}{cell_spans}>{html.escape(cell.content)}</{tag}>\"\n",
    "            table_html += \"</tr>\"\n",
    "        table_html += \"</table></figure>\"\n",
    "        return table_html\n",
    "\n",
    "    @staticmethod\n",
    "    def crop_image_from_pdf_page(\n",
    "        doc: pymupdf.Document, page_number: int, bbox_inches: tuple[float, float, float, float]\n",
    "    ) -> bytes:\n",
    "        \"\"\"\n",
    "        Crops a region from a given page in a PDF and returns it as an image.\n",
    "\n",
    "        :param pdf_path: Path to the PDF file.\n",
    "        :param page_number: The page number to crop from (0-indexed).\n",
    "        :param bbox_inches: A tuple of (x0, y0, x1, y1) coordinates for the bounding box, in inches.\n",
    "        :return: A PIL Image of the cropped area.\n",
    "        \"\"\"\n",
    "        # Scale the bounding box to 72 DPI\n",
    "        bbox_dpi = 72\n",
    "        bbox_pixels = [x * bbox_dpi for x in bbox_inches]\n",
    "        rect = pymupdf.Rect(bbox_pixels)\n",
    "        # Assume that the PDF has 300 DPI,\n",
    "        # and use the matrix to convert between the 2 DPIs\n",
    "        page_dpi = 300\n",
    "        page = doc.load_page(page_number)\n",
    "        pix = page.get_pixmap(matrix=pymupdf.Matrix(page_dpi / bbox_dpi, page_dpi / bbox_dpi), clip=rect)\n",
    "\n",
    "        img = Image.frombytes(\"RGB\", (pix.width, pix.height), pix.samples)\n",
    "        bytes_io = io.BytesIO()\n",
    "        img.save(bytes_io, format=\"PNG\")\n",
    "        return bytes_io.getvalue()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639a4d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa432fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_file_processors(\n",
    "    azure_credential: AsyncTokenCredential,\n",
    "    document_intelligence_service: Union[str, None],\n",
    "    document_intelligence_key: Union[str, None] = None,\n",
    "    local_pdf_parser: bool = False,\n",
    "    local_html_parser: bool = False,\n",
    "    search_images: bool = False,\n",
    "    use_content_understanding: bool = False,\n",
    "    content_understanding_endpoint: Union[str, None] = None,\n",
    "):\n",
    "    sentence_text_splitter = SentenceTextSplitter()\n",
    "\n",
    "    doc_int_parser: Optional[DocumentAnalysisParser] = None\n",
    "    # check if Azure Document Intelligence credentials are provided\n",
    "    if document_intelligence_service is not None:\n",
    "        documentintelligence_creds: Union[AsyncTokenCredential, AzureKeyCredential] = (\n",
    "            azure_credential if document_intelligence_key is None else AzureKeyCredential(document_intelligence_key)\n",
    "        )\n",
    "        doc_int_parser = DocumentAnalysisParser(\n",
    "            endpoint=f\"https://{document_intelligence_service}.cognitiveservices.azure.com/\",\n",
    "            credential=documentintelligence_creds,\n",
    "            use_content_understanding=use_content_understanding,\n",
    "            content_understanding_endpoint=content_understanding_endpoint,\n",
    "        )\n",
    "\n",
    "    pdf_parser: Optional[Parser] = None\n",
    "    if local_pdf_parser or document_intelligence_service is None:\n",
    "        pdf_parser = LocalPdfParser()\n",
    "    elif document_intelligence_service is not None:\n",
    "        pdf_parser = doc_int_parser\n",
    "    else:\n",
    "        logger.warning(\"No PDF parser available\")\n",
    "\n",
    "    html_parser: Optional[Parser] = None\n",
    "    if local_html_parser or document_intelligence_service is None:\n",
    "        html_parser = LocalHTMLParser()\n",
    "    elif document_intelligence_service is not None:\n",
    "        html_parser = doc_int_parser\n",
    "    else:\n",
    "        logger.warning(\"No HTML parser available\")\n",
    "\n",
    "    # These file formats can always be parsed:\n",
    "    file_processors = {\n",
    "        \".json\": FileProcessor(JsonParser(), SimpleTextSplitter()),\n",
    "        \".md\": FileProcessor(TextParser(), sentence_text_splitter),\n",
    "        \".txt\": FileProcessor(TextParser(), sentence_text_splitter),\n",
    "        \".csv\": FileProcessor(CsvParser(), sentence_text_splitter),\n",
    "    }\n",
    "    # These require either a Python package or Document Intelligence\n",
    "    if pdf_parser is not None:\n",
    "        file_processors.update({\".pdf\": FileProcessor(pdf_parser, sentence_text_splitter)})\n",
    "    if html_parser is not None:\n",
    "        file_processors.update({\".html\": FileProcessor(html_parser, sentence_text_splitter)})\n",
    "    # These file formats require Document Intelligence\n",
    "    if doc_int_parser is not None:\n",
    "        file_processors.update(\n",
    "            {\n",
    "                \".docx\": FileProcessor(doc_int_parser, sentence_text_splitter),\n",
    "                \".pptx\": FileProcessor(doc_int_parser, sentence_text_splitter),\n",
    "                \".xlsx\": FileProcessor(doc_int_parser, sentence_text_splitter),\n",
    "                \".png\": FileProcessor(doc_int_parser, sentence_text_splitter),\n",
    "                \".jpg\": FileProcessor(doc_int_parser, sentence_text_splitter),\n",
    "                \".jpeg\": FileProcessor(doc_int_parser, sentence_text_splitter),\n",
    "                \".tiff\": FileProcessor(doc_int_parser, sentence_text_splitter),\n",
    "                \".bmp\": FileProcessor(doc_int_parser, sentence_text_splitter),\n",
    "                \".heic\": FileProcessor(doc_int_parser, sentence_text_splitter),\n",
    "            }\n",
    "        )\n",
    "    return file_processors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120c70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up ingester\n",
    "file_processors = setup_file_processors(\n",
    "    azure_credential=azure_credential,\n",
    "    document_intelligence_service=os.getenv(\"AZURE_DOCUMENTINTELLIGENCE_SERVICE\"),\n",
    "    local_pdf_parser=os.getenv(\"USE_LOCAL_PDF_PARSER\", \"\").lower() == \"true\",\n",
    "    local_html_parser=os.getenv(\"USE_LOCAL_HTML_PARSER\", \"\").lower() == \"true\",\n",
    "    search_images=USE_GPT4V,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
